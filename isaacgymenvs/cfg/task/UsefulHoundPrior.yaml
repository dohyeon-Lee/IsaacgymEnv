# used to create the object
name: UsefulHoundPrior

physics_engine: 'physx'

env:
  test: false
  mode: Locomotion_vel # WholeBody_Locomotion | WholeBody_Manipulation | Locomotion_pos | Locomotion_vel | Manipulation
  ManipulationControlType: joint # osc | joint
  
  numEnvs: ${resolve_default:4096,${...num_envs}}
  numObservations: 0 #48 #49 #73 # 49 #66 # 48 #73 #15 # before exp4: 28
  numActions: 0 #12 # 12 # 12 #18 #6 #12 # (Hound)12 + (manipulator)6
  envSpacing: 3.  # [m]
  enableDebugVis: False

  ############################
  ## for manipulator #########
  houndarmPositionNoise: 0.0
  houndarmRotationNoise: 0.0
  houndarmDofNoise: 0.25
  

  terrain:
    terrainType: plane # trimesh # none, plane, or trimesh
    staticFriction: 1.0  # [-]
    dynamicFriction: 1.0  # [-]
    restitution: 0.        # [-]
    # rough terrain only:
    curriculum: true
    maxInitMapLevel: 0
    mapLength: 8.
    mapWidth: 8.
    numLevels: 10
    numTerrains: 20
    # terrain types: [smooth slope, rough slope, stairs up, stairs down, discrete]
    terrainProportions: [0.1, 0.1, 0.35, 0.25, 0.2]
    # tri mesh only:
    slopeTreshold: 0.5
  baseInitState:
    pos: [0.0, 0.0, 0.55] # x,y,z [m] # 0.52
    rot: [0.0, 0.0, 0.0, 1.0] # x,y,z,w [quat]
    vLinear: [0.0, 0.0, 0.0]  # x,y,z [m/s]
    vAngular: [0.0, 0.0, 0.0]  # x,y,z [rad/s]
  
  randomCommandPositionRanges:
    x: [-3., 3.]
    y: [-3., 3.]
    z: [0.8, 1]
    yaw: [-3.14, 3.14]
  randomCommandVelocityRanges:
    # train
    linear_x: [-1., 1.] # min max [m/s]
    linear_y: [-0.5, 0.5]   # min max [m/s]
    #yaw: [-3.14, 3.14]
    yaw: [-0.5, 0.5]    # min max [rad/s]

  randomArmCommandPositionRanges:
    x: [0.15, 0.75] 
    y: [-0.3, 0.3] 
    z: [0.65, 0.85] 

    sph_l: [0.20, 0.510]
    sph_p: [0.349, 1.134]
    sph_y: [-1.05, 1.05]
    sph_T: [1, 3]
  control:
    # PD Drive parameters:
    stiffness: 80.0  # [N*m/rad]
    damping: 2.0     # [N*m*s/rad]
    # action scale: target angle = actionScale * action + defaultAngle
    locoActionScale: 0.5
    maniActionScale: 1.0
    
    # decimation: Number of control action updates @ sim DT per policy DT
    decimation: 4

  defaultlocoJointAngles:  # = target angles when action = 0.0
    FL_roll_joint: 0.0    # [rad]
    RL_roll_joint: 0.0    # [rad]
    FR_roll_joint: -0.0   # [rad]
    RR_roll_joint: -0.0   # [rad]

    FL_hip_joint: 0.7854  # [rad]
    RL_hip_joint: 0.7854  # [rad]
    FR_hip_joint: 0.7854  # [rad]
    RR_hip_joint: 0.7854  # [rad]

    FL_knee_joint: -1.5708   # [rad]
    RL_knee_joint: -1.5708   # [rad]
    FR_knee_joint: -1.5708   # [rad]
    RR_knee_joint: -1.5708   # [rad]

  urdfAsset:
    file: "urdf/UsefulHound/urdf/Hound.urdf" #"urdf/UsefulHound/urdf/Hound.urdf"
    footName: "foot" # SHANK if collapsing fixed joint, FOOT otherwise
    kneeName: "thigh"
    shoulderName: "shoulder"
    calfName: "calf"
    endpointName: "end_link"
    collapseFixedJoints: false
    fixBaseLink: false
    defaultDofDriveMode: 4 # see GymDofDriveModeFlags (0 is none, 1 is pos tgt, 2 is vel tgt, 4 effort)

  learn:
    allowKneeContacts: True # TODO True
    # rewards
    linearVelocityXYRewardScale: 1.0    # Locomotion_vel, +
    angularVelocityZRewardScale: 0.5    # Locomotion_vel, +
    feetAirTimeRewardScale:  0.2        # Locomotion_vel, +
    linearVelocityZRewardScale: -0.4    # Locomotion_vel, -
    angularVelocityXYRewardScale: -0.05 # Locomotion_vel, -
    feetclearRewardScale: -10 # -1            # Locomotion_vel, -
    feetDragRewardScale: -0.05          # Locomotion_vel, -

    eefdistRewardScale: 1.5             # Manipulation, +
    eefvelRewardScale: 0                # Manipulation, +
    imitateRewardScale : 1 # 0.2        # Manipulation, +
    angvelrpyRewardScale : -0.1 #-1     # Manipulation, - # this scale is to big
    linvelxyzRewardScale : -0.1 #-1     # Manipulation, -
    baseposRewardScale : -0.1 #-1       # Manipulation, -
  
    manijointVelRewardScale: -0.0003
    manijointAccRewardScale: -0.00025 
    locojointVelRewardScale: -0.0003  #-0.00003 
    locojointAccRewardScale: -0.00005 # -0.0000025 
    torqueRewardScale: -0.0000025 
    actionRateRewardScale: -0.001 #-0.0001 
    hipRewardScale: -0.1

    terminalReward: 0.0
    orientationRewardScale: -1 #-0.1 
    baseHeightRewardScale: -1 #-0.1
    feetStumbleRewardScale: -0. 
    kneeCollisionRewardScale: -0.25 
    
    
    
    
    

    # normalization
    linearVelocityScale: 2.0
    angularVelocityScale: 0.25
    dofPositionScale: 1.0
    dofVelocityScale: 0.05

    # noise 
    addNoise: false
    noiseLevel: 1.0 # scales other values
    dofPositionNoise: 0.01
    dofVelocityNoise: 1.5
    linearVelocityNoise: 0.1
    angularVelocityNoise: 0.2
    gravityNoise: 0.05
    heightMeasurementNoise: 0.06

    #randomization
    randomizeFriction: true
    frictionRange: [0.5, 1.25]
    pushRobots: true
    pushInterval_s: 15
    commandInterval_s: 5
    # episode length in seconds
    episodeLength_s: 10 #4 #10 #20

  # viewer cam:
  viewer:
    refEnv: 0
    pos: [0, 0, 10]  # [m]
    lookat: [1., 1, 9]  # [m]

  # set to True if you use camera sensors in the environment
  enableCameraSensors: False

sim:
  dt: 0.005
  substeps: 1
  up_axis: "z"
  use_gpu_pipeline: ${eq:${...pipeline},"gpu"}
  gravity: [0.0, 0.0, -9.81]
  physx:
    num_threads: ${....num_threads}
    solver_type: ${....solver_type}
    use_gpu: ${contains:"cuda",${....sim_device}} # set to False to run on CPU
    num_position_iterations: 4
    num_velocity_iterations: 1
    contact_offset: 0.02
    rest_offset: 0.0
    bounce_threshold_velocity: 0.2
    max_depenetration_velocity: 100.0
    default_buffer_size_multiplier: 5.0
    max_gpu_contact_pairs: 8388608 # 8*1024*1024
    num_subscenes: ${....num_subscenes}
    contact_collection: 1 # 0: CC_NEVER (don't collect contact info), 1: CC_LAST_SUBSTEP (collect only contacts on last substep), 2: CC_ALL_SUBSTEPS (broken - do not use!)

task:
  randomize: False
